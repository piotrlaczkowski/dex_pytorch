## MODEL

Our data is split into continuous and categorical parts.
We first convert the categorical parts into embedding vectors based on the previously determined sizes and concatenate them with the continuous parts to feed to the rest of the network

### TODOs:

[] add tensorboard to the taining notebook, following: https://colab.research.google.com/drive/1rHBxrtopwtF8iLpmC_e7yl3TeDGrseJL?usp=sharing%3E#scrollTo=zK7-Gg69kMnG

[] check how to save the model for inference: https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_models_for_inference.html
